---
apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: llamastack-with-config
  namespace: {{ .Values.username }}-llama-stack
spec:
  replicas: 1
  server:
    containerSpec:
      name: llama-stack
      port: 8321
      env:
      - name: TELEMETRY_SINKS
        value: 'console, sqlite, otel_trace, otel_metric'
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://otel-collector-collector.observability-hub.svc.cluster.local:4318
      - name: OTEL_SERVICE_NAME
        value: llamastack
      - name: DEFAULT_MODEL_API_TOKEN
        valueFrom:
          secretKeyRef:
            name: {{ .Values.defaultModel.name }}
            key: apiKey
      # - name: LLAMA_3_2_3B_API_TOKEN
      #   valueFrom:
      #     secretKeyRef:
      #       name: llama-3-2-3b
      #       key: apiKey
      # - name: LLAMA_4_SCOUT_17B_16E_W4A16_API_TOKEN
      #   valueFrom:
      #     secretKeyRef:
      #       name: llama-4-scout-17b-16e-w4a16
      #       key: apiKey
      - name: TAVILY_API_KEY
        valueFrom:
          secretKeyRef:
            name: tavily-search-key
            key: tavily-search-api-key
    distribution:
      #name: remote-vllm
      image: quay.io/eformat/distribution-remote-vllm:0.2.15
    userConfig:
      configMapName: llama-stack-config
